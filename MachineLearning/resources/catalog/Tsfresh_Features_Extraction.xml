<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.11"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.11 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.11/schedulerjob.xsd"
    name="Tsfresh_Features_Extraction" projectName="4. Features Extraction"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2">
  <variables>
    <variable name="DOCKER_ENABLED" value="True" model="PA:Boolean"/>
  </variables>
  <description>
    <![CDATA[ Extract features from time series data based on TSFRESH library ]]>
  </description>
  <genericInformation>
    <info name="bucketName" value="time-series"/>
    <info name="workflow.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
    <info name="Documentation" value="https://doc.activeeon.com/latest/MLOS/MLOSUserGuide.html#_load_iris_dataset"/>
    <info name="group" value="public-objects"/>
  </genericInformation>
  <taskFlow>
    <task name="Tsfresh_Features_Extraction" >
      <description>
        <![CDATA[ Extract features from time series data based on TSFRESH library ]]>
      </description>
      <variables>
        <variable name="TIME_COLUMN" value="time" inherited="false" />
        <variable name="REF_COLUMN" value="" inherited="false" />
        <variable name="ALL_FEATURES" value="False" inherited="false" model="PA:Boolean"/>
        <variable name="LIMIT_OUTPUT_VIEW" value="5" inherited="false" />
        <variable name="DOCKER_ENABLED" value="True" inherited="true" model="PA:Boolean"/>
        <variable name="DOCKER_IMAGE" value="activeeon/dlm3" inherited="true" />
      </variables>
      <genericInformation>
        <info name="task.icon" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
        <info name="task.documentation" value="/automation-dashboard/styles/patterns/img/wf-icons/filled_filter.png"/>
      </genericInformation>
      <forkEnvironment javaHome="/usr" >
        <envScript>
          <script>
            <code language="python">
              <![CDATA[
if str(variables.get("DOCKER_ENABLED")).lower() == 'true':
  #Be aware, that the prefix command is internally split by spaces. So paths with spaces won't work.
  # Prepare Docker parameters 
  containerName = variables.get("DOCKER_IMAGE") 
  dockerRunCommand =  'docker run ' 
  dockerParameters = '--rm ' 
  # Prepare ProActive home volume 
  paHomeHost = variables.get("PA_SCHEDULER_HOME") 
  paHomeContainer = variables.get("PA_SCHEDULER_HOME") 
  proActiveHomeVolume = '-v '+paHomeHost +':'+paHomeContainer+' ' 
  # Prepare working directory (For Dataspaces and serialized task file) 
  workspaceHost = localspace 
  workspaceContainer = localspace 
  workspaceVolume = '-v '+localspace +':'+localspace+' ' 
  # Prepare container working directory 
  containerWorkingDirectory = '-w '+workspaceContainer+' ' 
  # Save pre execution command into magic variable 'preJavaHomeCmd', which is picked up by the node 
  preJavaHomeCmd = dockerRunCommand + dockerParameters + proActiveHomeVolume + workspaceVolume + containerWorkingDirectory + containerName
else:
  print("Fork environment disabled")
]]>
            </code>
          </script>
        </envScript>
      </forkEnvironment>
      <scriptExecutable>
        <script>
          <code language="cpython">
            <![CDATA[
import sys, bz2, uuid
import pandas as pd
import numpy as np

from tsfresh import extract_features
from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters

time_column = variables.get("TIME_COLUMN")
ref_column = variables.get("REF_COLUMN")
all_features = variables.get("ALL_FEATURES")
LIMIT_OUTPUT_VIEW = variables.get("LIMIT_OUTPUT_VIEW")

input_variables = {'task.dataframe_id': None}
for key in input_variables.keys():
  for res in results:
    value = res.getMetadata().get(key)
    if value is not None:
      input_variables[key] = value
      break

dataframe_id = input_variables['task.dataframe_id']
print("dataframe id (in): ", dataframe_id)

dataframe_json = variables.get(dataframe_id)
assert dataframe_json is not None
dataframe_json = bz2.decompress(dataframe_json).decode()

dataframe_df = pd.read_json(dataframe_json, orient='split')

# Add the list of features that need to be extracted 
# Check the full list of features on this link  http://tsfresh.readthedocs.io/en/latest/text/list_of_features.html
if all_features == "True":
  extraction_settings = {
    "length": None,
    "absolute_sum_of_changes": None,
    "abs_energy":None,
    #"sample_entropy": None,
    "number_peaks": [{"n": 2}],
    "number_cwt_peaks": [{"n": 2},{"n": 3}],
    "autocorrelation": [{"lag": 2},{"lag": 3}]
    #"value_count": #"large_standard_deviation": [{"r": 0.05}, {"r": 0.1}]
  }
#For convenience, three dictionaries are predefined and can be used right away (ComprehensiveFCParameters,MinimalFCParameters, EfficientFCParameters)
# MinimalFCParameters is set by default
else:
  extraction_settings = MinimalFCParameters()

extracted_features = extract_features(dataframe_df, column_id=ref_column, column_sort=time_column, default_fc_parameters=extraction_settings)
extracted_features[ref_column] = extracted_features.index

dataframe_json = extracted_features.to_json(orient='split').encode()
compressed_data = bz2.compress(dataframe_json)

dataframe_id = str(uuid.uuid4())
variables.put(dataframe_id, compressed_data)

print("dataframe id: ", dataframe_id)
print('dataframe size (original):   ', sys.getsizeof(dataframe_json), " bytes")
print('dataframe size (compressed): ', sys.getsizeof(compressed_data), " bytes")

resultMetadata.put("task.name", __file__)
resultMetadata.put("task.dataframe_id", dataframe_id)

LIMIT_OUTPUT_VIEW = 5 if LIMIT_OUTPUT_VIEW is None else int(LIMIT_OUTPUT_VIEW)
if LIMIT_OUTPUT_VIEW > 0:
  print("task result limited to: ", LIMIT_OUTPUT_VIEW, " rows")
  extracted_features = extracted_features.head(LIMIT_OUTPUT_VIEW).copy()

with pd.option_context('display.max_colwidth', -1):
    result = extracted_features.to_html(escape=False)

css_style="""
table {
  border: 1px solid #999999;
  text-align: center;
  border-collapse: collapse;
  width: 100%; 
}
td {
  border: 1px solid #999999;         
  padding: 3px 2px;
  font-size: 13px;
  border-bottom: 1px solid #999999;
  #border-bottom: 1px solid #FF8C00;  
  border-bottom: 1px solid #0B6FA4;   
}
th {
  font-size: 17px;
  font-weight: bold;
  color: #FFFFFF;
  text-align: center;
  background: #0B6FA4;
  #background: #E7702A;       
  #border-left: 2px solid #999999
  border-bottom: 1px solid #FF8C00;            
}
"""
result = """

            
            
            
            <!DOCTYPE html>
            <html>
              <head>
                <meta charset="UTF-8" />
                <style>{0}</style>
              </head>
              <body>{1}</body></html>
""".format(css_style, result)
result = result.encode('utf-8')
resultMetadata.put("file.extension", ".html")
resultMetadata.put("file.name", "output.html")
resultMetadata.put("content.type", "text/html")

print("END " + __file__)
]]>
            </code>
          </script>
        </scriptExecutable>
        <controlFlow block="none"></controlFlow>
        <post>
          <script>
            <code language="groovy">
              <![CDATA[
variables.put("PREVIOUS_PA_TASK_NAME", variables.get("PA_TASK_NAME"))
]]>
            </code>
          </script>
        </post>
        <metadata>
          <positionTop>
            386.1499938964844
        </positionTop>
          <positionLeft>
            994.6500244140625
        </positionLeft>
        </metadata>
      </task>
    </taskFlow>
  </job>